{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import io\n",
    "import lance\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Image Dataset Class to load the images from Lance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(data.Dataset):\n",
    "    def __init__(self, df, classes, transform=None):\n",
    "        self.df = df\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data = self.df.iloc[idx]['image']\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "        # Convert grayscale images to RGB\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.classes.index(self.df.iloc[idx]['category'])\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_into_pandas(uri):\n",
    "    ds = lance.dataset(uri)\n",
    "\n",
    "    # Accumulate data from batches into a list\n",
    "    data = []\n",
    "    for batch in tqdm(ds.to_batches(columns=[\"image\", \"filename\", \"category\", \"data_type\"], batch_size=10), desc=\"Loading batches\"):\n",
    "        tbl = batch.to_pandas()\n",
    "        data.append(tbl)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    df = pd.concat(data, ignore_index=True)\n",
    "    print(\"Pandas DataFrame is ready\")\n",
    "    print(\"Total Rows: \", df.shape[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, val_loader, model, criterion, optimizer, device, num_epochs=10):\n",
    "    model.to(device)  # Move model to the specified device\n",
    "    for epoch in range(num_epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)  # Move data to the specified device\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            wandb.log({\"Loss\": loss.item()})\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 64 == 63:  # Print every 64 mini-batches (batch size)\n",
    "                print(f'[{epoch + 1}, {i + 1:2d}] loss: {running_loss / 64:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for data_val in val_loader:\n",
    "                images_val, labels_val = data_val[0].to(device), data_val[1].to(device)\n",
    "                outputs_val = model(images_val)\n",
    "                _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                total_val += labels_val.size(0)\n",
    "                correct_val += (predicted_val == labels_val).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        print('Validation accuracy of the network: %.2f %%' % val_accuracy)\n",
    "        wandb.log({\"Validation Accuracy\": val_accuracy})\n",
    "\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_duration = end_epoch_time - start_epoch_time\n",
    "        wandb.log({\"Epoch Duration\": epoch_duration})\n",
    "        \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck')\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"cinic-10\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS Device:\", device)\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device:\", device)    \n",
    "\n",
    "# Load datasets\n",
    "training_df = loading_into_pandas('cinic/cinic_train.lance')\n",
    "testing_df = loading_into_pandas('cinic/cinic_test.lance')\n",
    "validation_df = loading_into_pandas('cinic/cinic_val.lance')\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomImageDataset(training_df, classes, transform=transform)\n",
    "test_dataset = CustomImageDataset(testing_df, classes, transform=transform)\n",
    "val_dataset = CustomImageDataset(validation_df, classes, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # 3 input channels, 6 output channels, 5x5 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 2x2 pooling\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 6 input channels, 16 output channels, 5x5 kernel\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) \n",
    "        self.fc2 = nn.Linear(120, 84) \n",
    "        self.fc3 = nn.Linear(84, 10) # There are 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "net = Net()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "train_model(train_loader, val_loader, net, criterion, optimizer, device, num_epochs=10)\n",
    "\n",
    "PATH = './cinic_net_lance.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Testing\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print('Accuracy of the network on the test images: %.2f %%' % accuracy)\n",
    "wandb.log({\"Test Accuracy\": accuracy})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
