{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lance Converter Script for any Image Dataset\n",
    "\n",
    "This script serves as a versatile tool for transforming any Image Dataset into the Lance format, enabling seamless integration and analysis. It provides a straightforward solution for converting diverse image datasets into a standardized format for enhanced compatibility and ease of use.\n",
    "\n",
    "For effortless access to pre-formatted CINIC-10 and mini-ImageNet datasets in Lance format, you can refer to the following links:\n",
    "\n",
    "CINIC-10 Dataset: https://www.kaggle.com/datasets/vipulmaheshwarii/cinic-10-lance-dataset\n",
    "\n",
    "mini-ImageNet Dataset: https://www.kaggle.com/datasets/vipulmaheshwarii/mini-imagenet-lance-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import lance\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the variable according to your Image dataset\n",
    "\n",
    "Assign the path to your image dataset to the variable `image_dataset`. This dataset should contain your images organized into training, testing, and validation folders. These images will be used to convert them into Lance format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = \"image_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Images\n",
    "\n",
    "The `process_images` function is the central component of this notebook, responsible for transforming images from the training, testing, and validation folders into Lance format. This format typically includes essential attributes such as `image`, `filename`, `category`, and `data_type`.\n",
    "\n",
    "Specifically, `image` represents the actual image data, `filename` denotes the name of the file, `category` indicates the category to which the image belongs, and `data_type` specifies whether the image is from the training, testing, or validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images():\n",
    "    # Get the current directory path\n",
    "    current_dir = os.getcwd()\n",
    "    images_folder = os.path.join(current_dir, image_dataset)\n",
    "    print(images_folder)\n",
    "\n",
    "    # Define schema for RecordBatch\n",
    "    schema = pa.schema([('image', pa.binary()), \n",
    "                        ('filename', pa.string()), \n",
    "                        ('category', pa.string()), \n",
    "                        ('data_type', pa.string())])\n",
    "\n",
    "    # Iterate over the data types (train, test, valid)\n",
    "    for data_type in ['train', 'test', 'val']:\n",
    "        data_type_folder = os.path.join(images_folder, data_type)\n",
    "        \n",
    "        # Iterate over the categories within each data type\n",
    "        for category in os.listdir(data_type_folder):\n",
    "            category_folder = os.path.join(data_type_folder, category)\n",
    "            \n",
    "            # Iterate over the images within each category\n",
    "            for filename in tqdm(os.listdir(category_folder), desc=f\"Processing {data_type} - {category}\"):\n",
    "                # Construct the full path to the image\n",
    "                image_path = os.path.join(category_folder, filename)\n",
    "\n",
    "                # Read and convert the image to a binary format\n",
    "                with open(image_path, 'rb') as f:\n",
    "                    binary_data = f.read()\n",
    "\n",
    "                image_array = pa.array([binary_data], type=pa.binary())\n",
    "                filename_array = pa.array([filename], type=pa.string())\n",
    "                category_array = pa.array([category], type=pa.string())\n",
    "                data_type_array = pa.array([data_type], type=pa.string())\n",
    "\n",
    "                # Yield RecordBatch for each image\n",
    "                yield pa.RecordBatch.from_arrays(\n",
    "                    [image_array, filename_array, category_array, data_type_array],\n",
    "                    schema=schema\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Lance Dataset\n",
    "\n",
    "This function, `write_to_lance`, is designed to convert a PyArrow Table into a Lance dataset. It begins by defining the schema for the Lance dataset, specifying fields such as `image`, `filename`, `category`, and `data_type` , make sure the schema is the same as the one defined in the `process_images` function.\n",
    "\n",
    "Once the schema is established, the function determines the path for saving the Lance file, leveraging the current working directory and the provided `image_dataset` variable. It then initializes a RecordBatchReader using the defined schema and the data obtained from the `process_images` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write PyArrow Table to Lance dataset\n",
    "def write_to_lance():\n",
    "    # Create an empty RecordBatchIterator\n",
    "    schema = pa.schema([\n",
    "        pa.field(\"image\", pa.binary()),\n",
    "        pa.field(\"filename\", pa.string()),\n",
    "        pa.field(\"category\", pa.string()),\n",
    "        pa.field(\"data_type\", pa.string())\n",
    "    ])\n",
    "\n",
    "    # Specify the path where you want to save the Lance file\n",
    "    current_dir = os.getcwd()\n",
    "    images_folder = os.path.join(current_dir, image_dataset)\n",
    "    lance_file_path = os.path.join(images_folder, f\"{image_dataset}.lance\")\n",
    "\n",
    "    reader = pa.RecordBatchReader.from_batches(schema, process_images())\n",
    "    lance.write_dataset(\n",
    "        reader,\n",
    "        lance_file_path,\n",
    "        schema,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
