{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5ejLihJETko"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils import data\n",
        "import torchvision.models as models\n",
        "\n",
        "import io\n",
        "import tqdm\n",
        "import lance\n",
        "import wandb\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the Image Classes, Transformation function and other utilities\n",
        "\n",
        "We are defining the different image classes that comes with the `cinic-10` and the transformation functions that needs to be applied to the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toSrp4xvFlwu"
      },
      "outputs": [],
      "source": [
        "# Define the image classes\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# transformation function \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NwTeSSQFyHz",
        "outputId": "4de238f1-17ef-4902-fa8c-2aebcdba1f8d"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"CUDA is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available, using CPU instead\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom Image Dataset Class\n",
        "\n",
        "We are going to use a custom Dataset class to load the images from the `cinic-10` Image Lance dataset. To know more about how we created a Lance image dataset, refer to `convert-any-image-dataset-to-lance.py` script in `converters` folder. \n",
        "\n",
        "\n",
        "Along with it, we are passing the adequate number of different classes and transformation function that needs to be applied to the images.\n",
        "\n",
        "To make sure the cnn architecture remains constant for all kind of images, we are going to apply the `RGB transformation` to the various images to maintain the same color space with a default setting of 3 channels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the custom dataset class\n",
        "class CustomImageDataset(data.Dataset):\n",
        "    def __init__(self, classes, lance_dataset, transform=None):\n",
        "        self.classes = classes\n",
        "        self.ds = lance.dataset(lance_dataset)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.ds.count_rows()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raw_img = self.ds.take([idx], columns=['image']).to_pydict()\n",
        "        img_data = raw_img['image'][0]\n",
        "\n",
        "        raw_label = self.ds.take([idx], columns=['label']).to_pydict()\n",
        "        label = raw_label['label'][0]\n",
        "\n",
        "        img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "        # Convert grayscale images to RGB\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = self.classes.index(label)\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model hyperparameters and Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2ZjNsWFF_jq"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "momentum = 0.9\n",
        "number_of_epochs = 50\n",
        "train_dataset_path = \"cinic/cinic_train.lance/\"\n",
        "test_dataset_path = \"cinic/cinic_test.lance/\"\n",
        "validation_dataset_path = \"cinic/cinic_val.lance/\"\n",
        "model_batch_size = 64\n",
        "batches_to_train = 256\n",
        "batches_to_val = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using a pre-trained `ResNet-34` architecture\n",
        "\n",
        "We are going to use a pre-trained `ResNet-34` architecture to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.resnet = models.resnet34(pretrained=True)\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Function\n",
        "\n",
        "`train_model` is the standard training function that we are going to use to train our CNN model. We will pass the relevant dataloaders, model, loss function, optimizer, device , batches to train and number of epochs to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uwpoeriGPlk"
      },
      "outputs": [],
      "source": [
        "def train_model(train_loader, val_loader, model, criterion, optimizer, device, num_epochs, batch_to_train, batch_to_val):\n",
        "    model.train()\n",
        "    total_start = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        total_batch_start = time.time()\n",
        "\n",
        "        with tqdm(enumerate(train_loader), total=batch_to_train, desc=f\"Epoch {epoch+1}\") as pbar_epoch:\n",
        "            for i, data in pbar_epoch:\n",
        "                if i >= batch_to_train:\n",
        "                    break\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                if i % 10 == 0:\n",
        "                    pbar_epoch.set_postfix({'Loss': loss.item()})\n",
        "                    pbar_epoch.update(10)\n",
        "\n",
        "        per_epoch_time = time.time() - total_batch_start\n",
        "        avg_loss = running_loss / batch_to_train\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} | Avg Loss: {avg_loss:.4f} | Time: {per_epoch_time:.4f} sec')\n",
        "        wandb.log({\"Loss\": loss.item()})\n",
        "        wandb.log({\"Epoch Duration\": per_epoch_time})\n",
        "\n",
        "    total_training_time = (time.time() - total_start) / 60\n",
        "    print(f\"Total Training Time: {total_training_time:.4f} mins\")\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            if i >= batch_to_val:\n",
        "                break\n",
        "            images_val, labels_val = data[0].to(device), data[1].to(device)\n",
        "            outputs_val = model(images_val)\n",
        "            _, predicted_val = torch.max(outputs_val.data, 1)\n",
        "            total_val += labels_val.size(0)\n",
        "            correct_val += (predicted_val == labels_val).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "    print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
        "    wandb.log({\"Validation Accuracy\": val_accuracy})\n",
        "    print('Finished Training')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "302JONSKGXY8"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomImageDataset(classes, train_dataset_path, transform=transform_train)\n",
        "test_dataset = CustomImageDataset(classes, test_dataset_path, transform=transform_test)\n",
        "val_dataset = CustomImageDataset(classes, validation_dataset_path, transform=transform_val)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=model_batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=model_batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=model_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wKfZZKqGgLW",
        "outputId": "b9a2e9b7-2752-4fa4-fe7e-bae0191e7a18"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"cinic\")\n",
        "\n",
        "net = Net(len(classes)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "trained_model = train_model(train_loader, val_loader, net, criterion, optimizer, device, number_of_epochs, batches_to_train, batches_to_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSfoUrdDP1hw"
      },
      "outputs": [],
      "source": [
        "PATH = 'cinic/cinic_resnet.pth'\n",
        "torch.save(trained_model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6jnPntXP5Yr",
        "outputId": "4dc3f222-d9b6-4286-8678-780d043184c3"
      },
      "outputs": [],
      "source": [
        "def test_model(test_loader, model, device):\n",
        "    model.eval()\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images_test, labels_test = data[0].to(device), data[1].to(device)\n",
        "            outputs_test = model(images_test)\n",
        "            _, predicted_test = torch.max(outputs_test.data, 1)\n",
        "            total_test += labels_test.size(0)\n",
        "            correct_test += (predicted_test == labels_test).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * correct_test / total_test\n",
        "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "test_model(test_loader, trained_model, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
