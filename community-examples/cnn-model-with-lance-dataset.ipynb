{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import io\n",
    "import lance\n",
    "import wandb\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Image Classes, Transformation function and other utilities\n",
    "\n",
    "We are defining the different image classes that comes with the `cinic-10` and the transformation function that needs to be applied to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvipulmaheshwari\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/vipul/Nova/Work/lancedb/lance-deeplearning-recipes/wandb/run-20240422_160330-h12p6iwu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vipulmaheshwari/cinic-10-test-4/runs/h12p6iwu' target=\"_blank\">glorious-aardvark-2</a></strong> to <a href='https://wandb.ai/vipulmaheshwari/cinic-10-test-4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vipulmaheshwari/cinic-10-test-4' target=\"_blank\">https://wandb.ai/vipulmaheshwari/cinic-10-test-4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vipulmaheshwari/cinic-10-test-4/runs/h12p6iwu' target=\"_blank\">https://wandb.ai/vipulmaheshwari/cinic-10-test-4/runs/h12p6iwu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Define the image classes\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck')\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"cinic-10-test-4\")\n",
    "\n",
    "# Determine the device to use (CPU or GPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS Device:\", device)\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Image Dataset Class\n",
    "\n",
    "We are going to use a custom Dataset class to load the images from the `cinic-10` Image Lance dataset. To know more about how we created a Lance image dataset, refer to `convert-any-image-dataset-to-lance.py` script in `converters` folder. \n",
    "\n",
    "\n",
    "Along with it, we are passing the adequate number of different classes and transformation function that needs to be applied to the images.\n",
    "\n",
    "To make sure the cnn architecture remains constant for all kind of images, we are going to apply the `RGB transformation` to the various images to maintain the same color space with a default setting of 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom dataset class\n",
    "class CustomImageDataset(data.Dataset):\n",
    "    def __init__(self, table, classes, transform=None):\n",
    "        self.table = table\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data = self.table[\"image\"][idx].as_py()\n",
    "        label = self.table[\"label\"][idx].as_py()\n",
    "\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "        # Convert grayscale images to RGB\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.classes.index(label)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model hyperparameters and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "number_of_epochs = 1\n",
    "train_dataset_path = \"cinic/cinic_train.lance\"\n",
    "test_dataset_path = \"cinic/cinic_test.lance\"\n",
    "validation_dataset_path = \"cinic/cinic_val.lance\"\n",
    "model_batch_size = 64\n",
    "dataframe_batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function\n",
    "\n",
    "`train_model` is the standard training function that we are going to use to train our CNN model. We will pass the relevant dataloaders, model, loss function, optimizer, device and number of epochs to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train_model(train_loader, val_loader, model, criterion, optimizer, device, num_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            wandb.log({\"Loss\": loss.item()})\n",
    "            running_loss += loss.item()\n",
    "            if i % model_batch_size == model_batch_size-1:\n",
    "                print(f'[{epoch + 1}, {i + 1:2d}] loss: {running_loss / model_batch_size:.2f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for data_val in val_loader:\n",
    "                images_val, labels_val = data_val[0].to(device), data_val[1].to(device)\n",
    "                outputs_val = model(images_val)\n",
    "                _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                total_val += labels_val.size(0)\n",
    "                correct_val += (predicted_val == labels_val).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        print('Validation accuracy of the network: %.2f %%' % val_accuracy)\n",
    "        wandb.log({\"Validation Accuracy\": val_accuracy})\n",
    "\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_duration = end_epoch_time - start_epoch_time\n",
    "        wandb.log({\"Epoch Duration\": epoch_duration})\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 64] loss: 2.30\n",
      "[1, 128] loss: 2.30\n",
      "[1, 192] loss: 2.30\n",
      "[1, 256] loss: 2.30\n",
      "[1, 320] loss: 2.30\n",
      "[1, 384] loss: 2.30\n",
      "[1, 448] loss: 2.30\n",
      "[1, 512] loss: 2.30\n",
      "[1, 576] loss: 2.30\n",
      "[1, 640] loss: 2.30\n",
      "[1, 704] loss: 2.30\n",
      "[1, 768] loss: 2.30\n",
      "[1, 832] loss: 2.30\n",
      "[1, 896] loss: 2.30\n",
      "[1, 960] loss: 2.30\n",
      "[1, 1024] loss: 2.30\n",
      "[1, 1088] loss: 2.30\n",
      "[1, 1152] loss: 2.30\n",
      "[1, 1216] loss: 2.30\n",
      "[1, 1280] loss: 2.30\n",
      "[1, 1344] loss: 2.29\n",
      "Validation accuracy of the network: 15.52 %\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 15.42 %\n"
     ]
    }
   ],
   "source": [
    "train_ds = lance.dataset(train_dataset_path)\n",
    "test_ds = lance.dataset(test_dataset_path)\n",
    "val_ds = lance.dataset(validation_dataset_path)\n",
    "\n",
    "train_ds_table = train_ds.to_table()\n",
    "test_ds_table = test_ds.to_table()\n",
    "val_ds_table = val_ds.to_table()\n",
    "\n",
    "train_dataset = CustomImageDataset(train_ds_table, classes, transform=transform)\n",
    "test_dataset = CustomImageDataset(test_ds_table, classes, transform=transform)\n",
    "val_dataset = CustomImageDataset(val_ds_table,  classes, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=model_batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=model_batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=model_batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate the model\n",
    "net = Net()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# Train the model\n",
    "train_model(train_loader, val_loader, net, criterion, optimizer, device, number_of_epochs)\n",
    "\n",
    "# Save and load the model\n",
    "PATH = './cinic_lance.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print('Accuracy of the network on the test images: %.2f %%' % accuracy)\n",
    "wandb.log({\"Test Accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
